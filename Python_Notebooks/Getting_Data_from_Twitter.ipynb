{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"02_Getting_Data_from_Twitter.ipynb","provenance":[]},"kernelspec":{"display_name":"Python [default]","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"bNxHQqJzKlRS","colab_type":"text"},"source":["# Getting Data from TWITTER \n","\n","- https://www.twitter.com/leehsienloong\n","- https://www.twitter.com/STcom\n","- https://www.twitter.com/stompsingapore"]},{"cell_type":"markdown","metadata":{"id":"bXgED82hKlRT","colab_type":"text"},"source":["# Getting Twitter API keys\n","\n","In order to access Twitter Streaming API, we need to get 4 pieces of information from Twitter: API key, API secret, Access token and Access token secret. Follow the steps below to get all 4 elements:\n","\n","- Create a Twitter account if you do not already have one.\n","- Go to https://apps.twitter.com/ and log in with your Twitter credentials.\n","- Click **Create New App**\n","- Fill out the form, agree to the terms, and click **Create your Twitter application**\n","- In the next page, click on **API keys** tab, and copy your **API key** and **API secret**.\n","- Scroll down and click **Create my access token**, and copy your **Access token** and **Access token secret**.\n"]},{"cell_type":"markdown","metadata":{"id":"rhspWXVGKlRU","colab_type":"text"},"source":["# Connecting to Twitter Streaming API and Download Data using `Tweepy`\n","\n","We will be using a Python library called **Tweepy** to connect to **Twitter Streaming API** and downloading the data. If you don't have Tweepy installed in your machine, go to this link ([github.com/tweepy/tweepy](https://github.com/tweepy/tweepy)), and follow the installation instructions.\n","\n","To install, simply launch **Terminal** and type:\n","- pip install tweepy \n","- **[or]** sudo pip install tweepy "]},{"cell_type":"code","metadata":{"id":"qa6sW6YyKlRV","colab_type":"code","colab":{}},"source":["# Variables that contains the user credentials to access Twitter API \n","access_token = '<access_token>'     # PLEASE USE YOUR OWN\n","access_token_secret = '<access_token_secret>'   # PLEASE USE YOUR OWN\n","consumer_key = '<consumer_key>'                              # PLEASE USE YOUR OWN\n","consumer_secret = '<consumer_key_secret>'  # PLEASE USE YOUR OWN"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2M8ZLDdCK2v5","colab_type":"code","colab":{}},"source":["!pip install tweepy"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rrD_ZaifKlRY","colab_type":"text"},"source":["# Twitter Search"]},{"cell_type":"code","metadata":{"id":"cZIH1i5ZKlRZ","colab_type":"code","colab":{}},"source":["import tweepy\n","from tweepy import OAuthHandler\n","\n","auth = OAuthHandler(consumer_key, consumer_secret)\n","auth.set_access_token(access_token, access_token_secret)\n","\n","api = tweepy.API(auth)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lRJX46msKlRa","colab_type":"code","colab":{}},"source":["results = api.search(q='obama', count=50, lang='en')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LNSFH8cQKlRd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":181},"outputId":"2b32ed88-b4a2-4ccd-d9b0-13141affeae2","executionInfo":{"status":"error","timestamp":1581597877739,"user_tz":-480,"elapsed":2788,"user":{"displayName":"Daniel Elias Becerra","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA4IvlMC-tOoTiy0gRjrEa4Qzo6FL82cncRN-8OZA=s64","userId":"01482411617204966660"}}},"source":["# Convert a result to JSON with \"._json\"\n","print(type(results[0]))\n","print(type(results[0]._json))"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-4282e397178f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"]}]},{"cell_type":"code","metadata":{"id":"_t5L-ssNKlRh","colab_type":"code","colab":{}},"source":["# Convert all the results into a `list of dictionaries`\n","list_of_status_dicts = []\n","\n","for result in results:\n","    list_of_status_dicts.append( result._json )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"av1hvfhCKlRj","colab_type":"code","colab":{}},"source":["# This code is the same as the code in the cell above, just that it's shorter.\n","# [Python list comprehension] Convert all the results into a `list of dictionaries`\n","list_of_status_dicts = [result._json for result in results]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"ACje5rW2KlRl","colab_type":"code","colab":{}},"source":["len(list_of_status_dicts)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JVjEFFcOldMp","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xnNR6DtSKlRo","colab_type":"code","colab":{}},"source":["list_of_status_dicts[0].keys()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nDImOh8Wlc0Z","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wzlb4pXplaSw","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bj0mbw56KlRr","colab_type":"code","colab":{}},"source":["list_of_status_dicts[0]['text']"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bKJPY3VNKlRt","colab_type":"text"},"source":["# Twitter Search (Advance)"]},{"cell_type":"code","metadata":{"id":"y95y10oUKlRu","colab_type":"code","colab":{}},"source":["query = 'trump'\n","max_tweets = 555\n","\n","searched_tweets = []\n","last_id = -1\n","while len(searched_tweets) < max_tweets:\n","    count = max_tweets - len(searched_tweets)\n","    try:\n","        new_tweets = api.search(q=query, lang='en', count=count, max_id=str(last_id - 1))\n","        if not new_tweets:\n","            break\n","        searched_tweets.extend(new_tweets)\n","        last_id = new_tweets[-1].id\n","    except tweepy.TweepError as e:\n","        # Depending on TweepError.code, one may want to retry or wait\n","        # to keep things simple, we will give up on an error\n","        break"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qSPi5-82KlRw","colab_type":"code","colab":{}},"source":["len(searched_tweets)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8K_E3z94KlR0","colab_type":"code","colab":{}},"source":["# Convert all the results into a `list of dictionaries`\n","list_of_status_dicts_2 = [x._json for x in searched_tweets]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1RfjEqywKlR2","colab_type":"code","colab":{}},"source":["len(list_of_status_dicts_2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VruiBKEdKlR5","colab_type":"code","colab":{}},"source":["list_of_status_dicts_2[0]['text']"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"irDAGfXdKlR8","colab_type":"text"},"source":["# Twitter Streaming\n","\n","The Streaming APIs give developers low latency access to Twitterâ€™s global stream of Tweet data. A proper implementation of a streaming client will be pushed messages indicating Tweets and other events have occurred, without any of the overhead associated with polling a REST endpoint.\n","\n","More info: https://dev.twitter.com/streaming/overview"]},{"cell_type":"code","metadata":{"id":"9NfrRcFWMZ9W","colab_type":"code","colab":{}},"source":["# mount google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZS-A2G0jMtF3","colab_type":"code","colab":{}},"source":["path = '/content/drive/My Drive/BT4222/twitter_streaming_data'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p-EP5teeM56i","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"e9A1eMJLKlR8","colab_type":"code","colab":{}},"source":["import os\n","from datetime import datetime\n","import json\n","import random\n","import re\n","from tweepy.streaming import StreamListener\n","from tweepy import OAuthHandler\n","from tweepy import Stream\n","\n","# This is a basic listener that just prints received tweets to stdout.\n","class StdOutListener(StreamListener):\n","\n","    def on_data(self, json_data):\n","        # print(json_data)\n","        filename = re.sub(r'\\s|\\/|:', r'_', '%s.txt' % str(datetime.now()))\n","        # fileloc = './twitter_stream_data/' + filename\n","        fileloc = os.path.join(path, filename)\n","  \n","        # 1% chance of printing out the file location\n","        if random.randint(0, 100) == 0:\n","            print(fileloc)\n","        # End of if statement.\n","            \n","        with open(fileloc, 'w') as f:\n","            f.write(json_data)\n","        return True\n","\n","    def on_error(self, status):\n","        print(status)\n","\n","\n","if __name__ == '__main__':\n","\n","    # This handles Twitter authetification and the connection to Twitter Streaming API\n","    l = StdOutListener()\n","    auth = OAuthHandler(consumer_key, consumer_secret)\n","    auth.set_access_token(access_token, access_token_secret)\n","    stream = Stream(auth, l)\n","\n","    # This line filter Twitter Streams to capture data by the keywords: 'python', 'javascript', 'ruby'\n","    stream.filter(track=['obama', 'trump', 'clinton'])\n","\n","\"\"\"\n","Note that this is a while loop! It runs until the cows come home!\n","To terminate this infinite loop, press the stop button in the iPython notebook's TOOLBAR.\n","\n","You will see a \"KeyboardInterrupt\" error message -- which is what you are supposed to get.\n","\"\"\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"In0Mjc8WKlR_","colab_type":"text"},"source":["### You should see the files in the `twitter_stream_data` folder\n","\n","![](./images/twitter_stream_data_folder.png)"]},{"cell_type":"markdown","metadata":{"id":"JMfzhASvKlSA","colab_type":"text"},"source":["# Reading Tweets"]},{"cell_type":"code","metadata":{"id":"vV9ZVRg7KlSB","colab_type":"code","colab":{}},"source":["import glob\n","# list_of_files = (glob.glob(\"./twitter_stream_data/*.txt\"))\n","list_of_files = (glob.glob(\"/content/drive/My Drive/BT4222/twitter_data/*txt\"))\n","len(list_of_files)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pj6L63CsKlSC","colab_type":"code","colab":{}},"source":["# Read all the TXT files into a \"list of dictionary objects\" called \"tweets_data\"\n","\n","tweets_data = []\n","\n","for fname in list_of_files:\n","    tweets_file = open(fname, \"r\")\n","    for line in tweets_file:\n","        try:\n","            tweet = json.loads(line)\n","            tweets_data.append(tweet)\n","        except:\n","            continue"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"62t8mNVhKlSE","colab_type":"text"},"source":["We can print the number of tweets using the command below."]},{"cell_type":"code","metadata":{"id":"fLMTDgF8KlSF","colab_type":"code","colab":{}},"source":["len(tweets_data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P6NSfIDXKlSI","colab_type":"code","colab":{}},"source":["tweets_data[0]['text']"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OKO405xBKlSL","colab_type":"text"},"source":["Next, we will structure the tweets data into a pandas DataFrame to simplify the data manipulation. We will start by creating an empty DataFrame called tweets using the following command."]},{"cell_type":"code","metadata":{"id":"zwl1rxuVKlSL","colab_type":"code","colab":{}},"source":["import pandas as pd\n","tweets = pd.DataFrame()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-VoFpLazKlSN","colab_type":"text"},"source":["Next, we will add 3 columns to the tweets DataFrame called text, lang, and country. text column contains the tweet, lang column contains the language in which the tweet was written, and country the country from which the tweet was sent."]},{"cell_type":"code","metadata":{"id":"8H1l_NMFKlSN","colab_type":"code","colab":{}},"source":["tweets['text'] = list(map(lambda tweet: tweet['text'] if 'text' in tweet else None, tweets_data))\n","tweets['lang'] = list(map(lambda tweet: tweet['lang'] if 'lang' in tweet else None, tweets_data))\n","tweets['country'] = list(map(lambda tweet: tweet['place']['country'] if ('place' in tweet and (tweet['place'] != None)) else None, tweets_data))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RLc4w-QCKlSQ","colab_type":"text"},"source":["Preview the **tweets** DataFrame"]},{"cell_type":"code","metadata":{"id":"Pzegy7kdKlSR","colab_type":"code","colab":{}},"source":["tweets.tail(10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GnsaZU-oKlST","colab_type":"code","colab":{}},"source":["tweets[  tweets['country'].notnull()  ].head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9DtnW4W2KlSV","colab_type":"text"},"source":["### Top 5 languages and Top 5 countries\n","\n","Next, we will create 2 charts: The first one describing the Top 5 languages in which the tweets were written, and the second the Top 5 countries from which the tweets were sent."]},{"cell_type":"code","metadata":{"id":"9iC_1Yw-KlSW","colab_type":"code","colab":{}},"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","plt.style.use('ggplot')\n","\n","tweets_by_lang = tweets['lang'].value_counts()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bfoMnCL1KlSZ","colab_type":"code","colab":{}},"source":["fig, ax = plt.subplots()\n","ax.tick_params(axis='x', labelsize=15)\n","ax.tick_params(axis='y', labelsize=10)\n","ax.set_xlabel('Languages', fontsize=15)\n","ax.set_ylabel('Number of tweets' , fontsize=15)\n","ax.set_title('Top 5 languages', fontsize=15, fontweight='bold')\n","tweets_by_lang[:5].plot(ax=ax, kind='bar', color='red')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NWWOxKtfKlSb","colab_type":"code","colab":{}},"source":["tweets_by_country = tweets['country'].value_counts()\n","\n","fig, ax = plt.subplots()\n","ax.tick_params(axis='x', labelsize=15)\n","ax.tick_params(axis='y', labelsize=10)\n","ax.set_xlabel('Countries', fontsize=15)\n","ax.set_ylabel('Number of tweets' , fontsize=15)\n","ax.set_title('Top 5 countries', fontsize=15, fontweight='bold')\n","tweets_by_country[:5].plot(ax=ax, kind='bar', color='blue')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"tnX8sFAeKlSf","colab_type":"text"},"source":["# Mining the Tweets\n","\n","Our main goals in these text mining tasks are: compare the popularity of Obama, Trump and Clinton and to retrieve links. We will do the following steps:\n","\n","- We will add tags to our tweets DataFrame in order to be able to manipualte the data easily.\n","- Extract links from tweets"]},{"cell_type":"markdown","metadata":{"id":"cb8scXmIKlSg","colab_type":"text"},"source":["First, we will create a function that checks if a specific keyword is present in a text. We will do this by using regular expressions. Python provides a library for regular expression called re. We will start by importing this library"]},{"cell_type":"code","metadata":{"id":"fUpR8QreKlSg","colab_type":"code","colab":{}},"source":["import re"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5dPM7pKgKlSi","colab_type":"text"},"source":["Next we will create a function called word_in_text(word, text). This function return True if a word is found in text, otherwise it returns False."]},{"cell_type":"code","metadata":{"id":"C4dFwbGRKlSj","colab_type":"code","colab":{}},"source":["def word_in_text(word, text):\n","    if word and text:\n","        word = word.lower()\n","        text = text.lower()\n","        match = re.search(word, text)\n","        if match:\n","            return True\n","    return False"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xe419ohDKlSk","colab_type":"text"},"source":["Next, we will add 3 columns to our tweets DataFrame."]},{"cell_type":"code","metadata":{"id":"oXfbJcTAKlSl","colab_type":"code","colab":{}},"source":["tweets['obama'] = tweets['text'].apply(lambda tweet: word_in_text('obama', tweet))\n","tweets['trump'] = tweets['text'].apply(lambda tweet: word_in_text('trump', tweet))\n","tweets['clinton'] = tweets['text'].apply(lambda tweet: word_in_text('clinton', tweet))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QIYu0-uTKlSm","colab_type":"text"},"source":["The modified DataFrame looks like this."]},{"cell_type":"code","metadata":{"id":"X9ZzEqn_KlSn","colab_type":"code","colab":{}},"source":["tweets.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"16eKylUYKlSp","colab_type":"text"},"source":["We can calculate the number of tweets for each person as follows:"]},{"cell_type":"code","metadata":{"id":"jdNInDp0KlSq","colab_type":"code","colab":{}},"source":["print(tweets['obama'].value_counts()[True])\n","print(tweets['trump'].value_counts()[True])\n","print(tweets['clinton'].value_counts()[True])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zcg6yILwKlSw","colab_type":"text"},"source":["We can make a simple comparaison chart by executing the following:"]},{"cell_type":"code","metadata":{"id":"wn2mzODwKlSw","colab_type":"code","colab":{}},"source":["politicians = ['obama', 'trump', 'clinton']\n","tweets_by_politicians = [tweets['obama'].value_counts()[True], tweets['trump'].value_counts()[True], tweets['clinton'].value_counts()[True]]\n","\n","x_pos = list(range(len(politicians)))\n","width = 0.8\n","fig, ax = plt.subplots()\n","plt.bar(x_pos, tweets_by_politicians, width, alpha=1, color='g')\n","\n","# Setting axis labels and ticks\n","ax.set_ylabel('Number of tweets', fontsize=15)\n","ax.set_title('Ranking: Obama vs. Trump vs. Clinton', fontsize=10, fontweight='bold')\n","ax.set_xticks([p + 0.4 * width for p in x_pos])\n","ax.set_xticklabels(politicians)\n","plt.grid()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dcZSlPKsKlS0","colab_type":"text"},"source":["# Extracting links from the tweets\n","\n","Now, we want to retrieve links in the tweets. We will start by creating a function that uses regular expressions for retrieving link that start with **\"http://\"** or **\"https://\"** from a text. This function will return the url if found, otherwise it returns an empty string."]},{"cell_type":"code","metadata":{"id":"BKaRb0P0KlS1","colab_type":"code","colab":{}},"source":["def extract_link(text):\n","    try:\n","        regex = r'https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+'\n","        match = re.search(regex, text)\n","        if match:\n","            return match.group()\n","        return ''\n","    except:\n","        return ''"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4aXG2IiiKlS2","colab_type":"text"},"source":["Next, we will add a column called link to our tweets DataFrame. This column will contain the urls information."]},{"cell_type":"code","metadata":{"id":"_wKIU8XLKlS2","colab_type":"code","colab":{}},"source":["tweets['link'] = tweets['text'].apply(lambda tweet: extract_link(tweet))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"riDCaiTeKlS4","colab_type":"text"},"source":["The modified DataFrame looks like this."]},{"cell_type":"code","metadata":{"scrolled":true,"id":"gbj9J53zKlS6","colab_type":"code","colab":{}},"source":["tweets.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MCgxFscLKlS8","colab_type":"code","colab":{}},"source":["tweets.shape"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NorUIPWOKlS_","colab_type":"text"},"source":["Next, we will create a new DataFrame called **tweets_with_link**. \n","This DataFrame is a subset of tweets DataFrame and contains all tweets that have a link."]},{"cell_type":"code","metadata":{"id":"3yIiZJMrKlS_","colab_type":"code","colab":{}},"source":["tweets_with_link = tweets[ tweets['link'] != ''].copy()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8etrEi-ZKlTC","colab_type":"code","colab":{}},"source":["tweets_with_link.head(3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cY5gNpyqKlTF","colab_type":"code","colab":{}},"source":["tweets_with_link.shape"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A58fc12yKlTH","colab_type":"text"},"source":["We can now print out all links for **obama**, **trump**, and **clinton** by executing the commands below:"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"sIOH6mUSKlTH","colab_type":"code","colab":{}},"source":["print(tweets_with_link[tweets_with_link['obama']   == True]['link'])\n","print(tweets_with_link[tweets_with_link['trump']   == True]['link'])\n","print(tweets_with_link[tweets_with_link['clinton'] == True]['link'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gmmx8JLaKlTJ","colab_type":"code","colab":{}},"source":["# Now say we want to read one of the links above, https://t.co/oua32nXu8W\n","\n","# Read the HTML source of the URL: https://t.co/oua32nXu8W\n","import urllib.request\n","url = 'https://t.co/oua32nXu8W'\n","request = urllib.request.Request(url)\n","response = urllib.request.urlopen(request)\n","html = response.read()\n","try:\n","    html = html.decode('utf-8')\n","except:\n","    html = html.decode('unicode_escape')\n","\n","# Import BeautifulSoup\n","from bs4 import BeautifulSoup\n","soup = BeautifulSoup(html, 'html.parser')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vgz8vo8EKlTM","colab_type":"code","colab":{}},"source":["# See the title of the HTML document\n","\n","soup.title"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6M8PtvjKKlTP","colab_type":"code","colab":{}},"source":["# Extract all the paragraphs (p) and print out the content\n","\n","for paragraph in soup.find_all('p'):\n","    if paragraph.string is not None:\n","        print(paragraph.string)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tJ3seeqiKlTQ","colab_type":"text"},"source":["# Conclusion\n","\n","In this tutorial, we covered many techniques used in text mining. The code here can be:\n","1. modified to create a deeper analysis, or  \n","2. adapted to another use case. "]},{"cell_type":"markdown","metadata":{"id":"OE57ugqVKlTR","colab_type":"text"},"source":["# References\n","- http://en.wikipedia.org/wiki/Text_mining\n","- http://en.wikipedia.org/wiki/Word-sense_disambiguation\n","- http://en.wikipedia.org/wiki/Regular_expression"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"458ewyp3KlTR","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"A9U3OXv8KlTS","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"1TjuI8DqKlTT","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"fLXxjPwqKlTU","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"Y75-tiGQKlTY","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"FceCet76KlTZ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}